{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib as hl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/narayani/Desktop/IIITB/Sem6/ML/ML_Project/Housing_Linear Regression/data/housing.csv')\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def splitTrainData(total_data, ratio):\n",
    "    indices_Shuffled = np.random.permutation(len(total_data))\n",
    "    test_data_size = int(len(total_data)* ratio)\n",
    "    indices_Test = indices_Shuffled[:test_data_size]\n",
    "    indices_Train = indices_Shuffled[test_data_size:]\n",
    "    return total_data.iloc[indices_Train], total_data.iloc[indices_Test]\n",
    "training_data, test_data = splitTrainData(data, 0.3)'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "training_set, test_set = train_test_split(data,test_size=0.2,random_state = 42)\n",
    "#print(\"Train: \",len(train_set), \" +  Test: \" , len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_training = training_data.drop(['median_house_value', 'ocean_proximity'],axis =1)\n",
    "# Y_labels = training_data[\"median_house_value\"].copy()\n",
    "\n",
    "# from sklearn.preprocessing import Imputer\n",
    "# imputer = Imputer(strategy = \"median\")\n",
    "\n",
    "# imputer.fit(X_training)\n",
    "# #imputer.statistics_\n",
    "# #X_training.median().values\n",
    "\n",
    "# X_imp = imputer.transform(X_training)\n",
    "# X_inp = pd.DataFrame(X_imp, columns = X_training.columns)\n",
    "\n",
    "# X_data = X_inp.as_matrix()\n",
    "# Y = Y_labels.as_matrix()\n",
    "\n",
    "# X = np.c_[np.ones((len(X_inp),1)),X_data]\n",
    "# #X= (X - X.mean())/(X+X.std())\n",
    "# theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y)\n",
    "\n",
    "# theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process the data:\n",
    "                To remove \"NAN-Values\" wherever there in the data. And Since, column named \"Ocean Proximity\" is a text field, we have encode it, so that it can be used for ML-Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData ( train_set ):\n",
    "#Removing the target values and copying them as labels/target value for feature values of each data-point.\n",
    "#new data is the data without the target values\n",
    "    new_data = train_set.drop(\"median_house_value\", axis = 1)\n",
    "    labels = train_set[\"median_house_value\"].copy()\n",
    "    \n",
    "#Imputer is used to remove all the NAN values in the dataset, but after the removal of the text field i.e \"ocean_proximity\"\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    imputer = Imputer(strategy = \"median\")  \n",
    "    ntx_data = new_data.drop(\"ocean_proximity\", axis =1)\n",
    "    imputer.fit(ntx_data)\n",
    "    ntx_data_imp = imputer.transform(ntx_data)\n",
    "    \n",
    "#Converting into Pandas-Dataframe. \n",
    "    ntx_data_inp = pd.DataFrame(ntx_data_imp, columns = ntx_data.columns,index = list(ntx_data.index.values))\n",
    "    \n",
    "#Encoding the text-field \"ocean_proximity\".\n",
    "    housing_cat = new_data['ocean_proximity']\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    housing_cat_encoded, housing_categories = housing_cat.factorize()\n",
    "    encoder = OneHotEncoder()\n",
    "#Reshaping housing_cat_encoder as it is 1-D array, but fit_transform expects a 2-D array.\n",
    "    housing_cat_1hot =encoder.fit_transform(housing_cat_encoded.reshape(-1,1))\n",
    "    (housing_cat_1hot.toarray())\n",
    "\n",
    "    import category_encoders as c_enc\n",
    "    encoder = c_enc.OneHotEncoder()\n",
    "    housing_cat_reshaped = housing_cat.values.reshape(-1,1)\n",
    "    encoder.fit(housing_cat_reshaped)\n",
    "    \n",
    "    X_cleaned = encoder.transform(housing_cat_reshaped)\n",
    "#Converting Encoded values for \"ocean_proximity\" to matrix\n",
    "    enc_data = X_cleaned.as_matrix()\n",
    "    \n",
    "#Feature Scaling for data without the encoded values for \"ocean_proximity\":\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(ntx_data_inp)\n",
    "    data_without_enc = scaler.transform(ntx_data_inp)\n",
    "\n",
    "#data without encoded values is being appended by the encoded values to get the complete data for computation.\n",
    "    data_training = np.append(data_without_enc, enc_data, axis = 1)\n",
    "    data_training = X = np.c_[np.ones((len(data_training),1)),data_training]\n",
    "    \n",
    "    \n",
    "    return data_training, labels\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the Training Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data , training_labels = preprocessData(training_set)\n",
    "testing_data , testing_labels = preprocessData(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# lin_reg = LinearRegression()\n",
    "# lin_reg.fit(training_data, training_labels)\n",
    "# lin_reg.predict(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter matrix from Normal Equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([199021.96620438, -53826.64801649, -54415.6961445 ,  13889.86618856,\n",
       "       -13094.25116219,  43068.18184187, -43403.43242732,  18382.19632373,\n",
       "        75167.77476625,  24308.95045207, -18908.84578241,  20877.81037892,\n",
       "        15741.16816144, 157002.88299432,      0.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#temp = (training_data.T).dot(training_data)\n",
    "\n",
    "theta = np.linalg.pinv(training_data.T.dot(training_data)).dot(training_data.T).dot(training_labels)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted labels for training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([188628.07724361, 290379.8948687 , 250985.48476349, ...,\n",
       "       194624.05524513, 281818.52422053, 271572.8418584 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predicted_Y = training_data.dot(theta.T)\n",
    "train_predicted_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = test_data.drop(['median_house_value','ocean_proximity'], axis =1)\n",
    "# Y_actuals = test_data[\"median_house_value\"].copy()\n",
    "\n",
    "# imputer.fit(X_test)\n",
    "# X_test_imp = imputer.transform(X_test)\n",
    "# test_inp = pd.DataFrame(X_test_imp, columns = X_test.columns)\n",
    "\n",
    "# data_test = test_inp.as_matrix()\n",
    "# actual_Y = Y_actuals.as_matrix()\n",
    "\n",
    "# #test_inp.info()\n",
    "# actual_Y\n",
    "\n",
    "#test = np.c_[np.ones((len(test_inp)),1),data_test]\n",
    "#test = np.c_[np.ones((len(test_inp),1)),data_test]\n",
    "#test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicated labels for test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 98165.82772806, 168705.1233016 , 223015.48407995, ...,\n",
       "       444695.41566959, 166431.68590505, 185544.84958196])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predicted_Y = testing_data.dot(theta.T)\n",
    "test_predicted_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_housing = data.drop(['median_house_value', 'ocean_proximity'],axis =1)\n",
    "# Y_housing = data[\"median_house_value\"].copy()\n",
    "\n",
    "# imputer.fit(X_housing)\n",
    "\n",
    "# X_housing_imp = imputer.transform(X_housing)\n",
    "# X_housing_inp = pd.DataFrame(X_housing_imp, columns = X_housing.columns)\n",
    "\n",
    "# X_housing_data = X_housing_inp.as_matrix()\n",
    "# housing_Y = Y_housing.as_matrix()\n",
    "# housing = np.c_[np.ones((len(X_housing_inp),1)),X_housing_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the Complete Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data , housing_labels = preprocessData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([202257.61270761, -52952.95152846, -53767.62485624,  13312.88334575,\n",
       "       -10320.06092603,  29920.76507621, -44490.47744263,  29746.22226671,\n",
       "        73636.15586366,  13281.98627461,  16979.3879357 , -22787.0108087 ,\n",
       "        21738.14154797, 173045.10775805,      0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calulating new Parameter Matrix for the complete dataset\n",
    "theta_new = np.linalg.pinv(housing_data.T.dot(housing_data)).dot(housing_data.T).dot(housing_labels)\n",
    "theta_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicated labels for whole housing dataset without splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([408492.35829822, 423996.66388553, 378466.63041436, ...,\n",
       "        40399.753241  ,  50937.88670863,  67523.43037025])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_predicted_Y = housing_data.dot(theta_new.T)\n",
    "\n",
    "housing_predicted_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Traning Data: 68433.93736666226\n",
      "RMSE for Test Data: 75275.2554019648\n",
      "RMSE for Housing Data taken without splitting: 68709.32557762168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_mse = mean_squared_error(testing_labels, test_predicted_Y)\n",
    "train_mse = mean_squared_error(training_labels,train_predicted_Y)\n",
    "housing_mse = mean_squared_error(housing_labels, housing_predicted_Y)\n",
    "\n",
    "\n",
    "print \"RMSE for Traning Data: \"+ str(np.sqrt(train_mse))\n",
    "print \"RMSE for Test Data: \" + str(np.sqrt(test_mse))\n",
    "print \"RMSE for Housing Data taken without splitting: \"+ str(np.sqrt(housing_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
